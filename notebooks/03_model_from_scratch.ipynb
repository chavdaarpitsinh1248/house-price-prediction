{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94217aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/house_prices.csv\")\n",
    "\n",
    "selected_columns = [\n",
    "    \"sqft_living\",\n",
    "    \"bedrooms\",\n",
    "    \"bathrooms\",\n",
    "    \"floors\",\n",
    "    \"view\",\n",
    "    \"price\"\n",
    "]\n",
    "\n",
    "df = df[selected_columns].copy()\n",
    "\n",
    "X = df.drop(\"price\", axis=1).values\n",
    "y = df[\"price\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20c1ef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_size=0.2, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(len(X))\n",
    "    test_count = int(len(X) * test_size)\n",
    "    \n",
    "    test_idx = indices[:test_count]\n",
    "    train_idx = indices[test_count:]\n",
    "    \n",
    "    return X[train_idx], X[test_idx], y[train_idx], y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d740848",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13216d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(X):\n",
    "    mean = np.mean(X, axis=0)\n",
    "    std = np.std(X, axis=0)\n",
    "    return (X - mean) / std, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17500ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm, mean, std = normalize_features(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ae87a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3680, 5), (3680,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_norm.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80e17a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train_norm.shape[1]\n",
    "\n",
    "W = np.zeros(n_features)\n",
    "b = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "504f006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, W, b):\n",
    "    return np.dot(X, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f80062f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a811fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradients(X, y, y_pred):\n",
    "    n = len(y)\n",
    "    dW = (-2 / n) * np.dot(X.T, (y - y_pred))\n",
    "    db = (-2 / n) * np.sum(y - y_pred)\n",
    "    return dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbfdc722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, W, b, learning_rate=0.01, epochs=1000):\n",
    "    loss_history = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        y_pred = predict(X, W, b)\n",
    "        loss = mean_squared_error(y, y_pred)\n",
    "        loss_history.append(loss)\n",
    "        \n",
    "        dW, db = compute_gradients(X, y, y_pred)\n",
    "        \n",
    "        W -= learning_rate * dW\n",
    "        b -= learning_rate * db\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "            \n",
    "    return W, b, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ca3d66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 438945531125.1893\n",
      "Epoch 100, Loss: 81335355303.2312\n",
      "Epoch 200, Loss: 73156018667.7202\n",
      "Epoch 300, Loss: 72020043558.4249\n",
      "Epoch 400, Loss: 71618878830.4474\n",
      "Epoch 500, Loss: 71458585946.1854\n",
      "Epoch 600, Loss: 71392623378.6279\n",
      "Epoch 700, Loss: 71365106459.1831\n",
      "Epoch 800, Loss: 71353548578.2838\n",
      "Epoch 900, Loss: 71348677267.8994\n"
     ]
    }
   ],
   "source": [
    "W, b, loss_history = gradient_descent(\n",
    "    X_train_norm,\n",
    "    y_train,\n",
    "    W,\n",
    "    b,\n",
    "    learning_rate=0.01,\n",
    "    epochs=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fe519ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_l2_loss(y_true, y_pred, W, lambda_):\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    l2_penalty = lambda_ * np.sum(W ** 2)\n",
    "    return mse + l2_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c62d192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradients_l2(X, y, y_pred, W, lambda_):\n",
    "    n = len(y)\n",
    "    dW = (-2 / n) * np.dot(X.T, (y - y_pred)) + 2 * lambda_ * W\n",
    "    db = (-2 / n) * np.sum(y - y_pred)\n",
    "    return dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cdadbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_l2(X, y, W, b, learning_rate=0.01, epochs=1000, lambda_=0.1):\n",
    "    loss_history = []\n",
    "    for epoch in range(epochs):\n",
    "        y_pred = predict(X, W, b)\n",
    "        loss = mse_l2_loss(y, y_pred, W, lambda_)\n",
    "        loss_history.append(loss)\n",
    "        \n",
    "        dW, db = compute_gradients_l2(X, y, y_pred, W, lambda_)\n",
    "        \n",
    "        W -= learning_rate * dW\n",
    "        b -= learning_rate * db\n",
    "        \n",
    "    return W, b, loss_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
